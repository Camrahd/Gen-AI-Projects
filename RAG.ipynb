{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUK2Kgk2lmAuacjpwF6vRu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camrahd/Gen-AI-Projects/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Install dependencies**"
      ],
      "metadata": {
        "id": "7YqBBo-PkNQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "  langchain==0.3.0 \\\n",
        "  langchain-openai==0.3.0 \\\n",
        "  langchain-community==0.3.0 \\\n",
        "  langchain-text-splitters==0.3.0 \\\n",
        "  faiss-cpu \\\n",
        "  pypdf \\\n",
        "  tiktoken"
      ],
      "metadata": {
        "id": "89KZiY9FjiyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step2: import dependecies\n",
        "\n",
        "import os\n",
        "from google.colab import userdata, files\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "\n",
        "# === STEP 3: Load OpenAI API key from Colab Secrets ===\n",
        "\"\"\"\n",
        "In Colab:\n",
        "- Go to:  üîê \"Editor\" (left sidebar) ‚Üí \"Secrets\" ‚Üí \"Add new secret\"\n",
        "- Name: OPENAI_API_KEY\n",
        "- Value: your actual OpenAI API key\n",
        "\"\"\"\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "    if not os.environ[\"OPENAI_API_KEY\"]:\n",
        "        raise ValueError(\"Empty OPENAI_API_KEY.\")\n",
        "    print(\"‚úÖ API key loaded from Colab secrets!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Could not load OPENAI_API_KEY from Colab secrets.\")\n",
        "    print(\"Error:\", e)\n",
        "    raise\n",
        "\n",
        "\n",
        "# === STEP 4: Upload PDF/TXT files ===\n",
        "print(\"\\nüìÑ Upload one or more PDF/TXT files:\")\n",
        "uploaded = files.upload()\n",
        "file_names = list(uploaded.keys())\n",
        "print(\"‚úÖ Uploaded files:\", file_names)\n",
        "\n",
        "# === STEP 5: Load ALL Documents ===\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "\n",
        "all_docs = []\n",
        "\n",
        "for file_path in file_names:\n",
        "    print(f\"\\nüì• Loading: {file_path}\")\n",
        "    if file_path.lower().endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    elif file_path.lower().endswith(\".txt\"):\n",
        "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "    else:\n",
        "        print(f\"‚õî Skipping {file_path}: only .pdf or .txt supported.\")\n",
        "        continue\n",
        "\n",
        "    docs = loader.load()\n",
        "    print(f\"   ‚Üí Loaded {len(docs)} page(s)/document(s)\")\n",
        "    all_docs.extend(docs)\n",
        "\n",
        "print(f\"\\n‚úÖ Total documents/pages loaded: {len(all_docs)}\")\n",
        "\n",
        "\n",
        "# === STEP 6: Split into Chunks ===\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        ")\n",
        "\n",
        "texts = splitter.split_documents(all_docs)\n",
        "print(f\"‚úÖ Split into {len(texts)} chunks\")\n",
        "\n",
        "\n",
        "# === STEP 7: Create Embeddings & FAISS Vector Store ===\n",
        "\n",
        "print(\"\\nüîç Creating embeddings and FAISS vector store...\")\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Extract raw text + metadata for FAISS\n",
        "texts_list = [doc.page_content for doc in texts]\n",
        "metadatas = [doc.metadata for doc in texts]\n",
        "\n",
        "vectorstore = FAISS.from_texts(\n",
        "    texts=texts_list,\n",
        "    embedding=embeddings,\n",
        "    metadatas=metadatas,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Vector DB (FAISS) ready!\")\n",
        "\n",
        "\n",
        "# === STEP 8: Build RetrievalQA Chain (Simple RAG) ===\n",
        "\"\"\"\n",
        "We use:\n",
        "- retriever = FAISS index (semantic search over chunks)\n",
        "- LLM = ChatOpenAI (chat completion model)\n",
        "- chain = RetrievalQA: it retrieves top-k chunks and \"stuffs\" them into the prompt.\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",   # or \"gpt-4o\", \"gpt-3.5-turbo\", etc.\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # simplest: concatenate retrieved chunks into context\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,  # optional: to inspect which chunks were used\n",
        ")\n",
        "\n",
        "print(\"\\nü§ñ RAG Bot is READY! Type questions about your document.\")\n",
        "print(\"Type 'exit' or 'quit' to stop.\\n\")\n",
        "\n",
        "\n",
        "# === STEP 9: Interactive Loop ===\n",
        "while True:\n",
        "    query = input(\"You: \").strip()\n",
        "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"RAG: Goodbye! üëã\")\n",
        "        break\n",
        "\n",
        "    if not query:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        result = qa.invoke({\"query\": query})\n",
        "        answer = result[\"result\"]\n",
        "        print(f\"\\nRAG: {answer}\\n\")\n",
        "\n",
        "        # Optional: show which document chunks were used\n",
        "        # (helpful for debugging / transparency)\n",
        "        print(\"--- Sources ---\")\n",
        "        for i, doc in enumerate(result[\"source_documents\"], start=1):\n",
        "            src = doc.metadata.get(\"source\", \"N/A\")\n",
        "            page = doc.metadata.get(\"page\", \"N/A\")\n",
        "            print(f\"[{i}] source={src}, page={page}\")\n",
        "        print(\"---------------\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8fZXMVgvlx9X",
        "outputId": "010c4266-ac1b-4504-86c4-d4b7c8416489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key loaded from Colab secrets!\n",
            "\n",
            "üìÑ Upload one or more PDF/TXT files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08d9377d-2b61-4856-996f-ee528f26ca28\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08d9377d-2b61-4856-996f-ee528f26ca28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Aetna_Tutorial.pdf to Aetna_Tutorial (2).pdf\n",
            "Saving Educosys_Agentic_Hackathon_Guidelines.pdf to Educosys_Agentic_Hackathon_Guidelines (5).pdf\n",
            "‚úÖ Uploaded files: ['Aetna_Tutorial (2).pdf', 'Educosys_Agentic_Hackathon_Guidelines (5).pdf']\n",
            "\n",
            "üì• Loading: Aetna_Tutorial (2).pdf\n",
            "   ‚Üí Loaded 3 page(s)/document(s)\n",
            "\n",
            "üì• Loading: Educosys_Agentic_Hackathon_Guidelines (5).pdf\n",
            "   ‚Üí Loaded 2 page(s)/document(s)\n",
            "\n",
            "‚úÖ Total documents/pages loaded: 5\n",
            "‚úÖ Split into 6 chunks\n",
            "\n",
            "üîç Creating embeddings and FAISS vector store...\n",
            "‚úÖ Vector DB (FAISS) ready!\n",
            "\n",
            "ü§ñ RAG Bot is READY! Type questions about your document.\n",
            "Type 'exit' or 'quit' to stop.\n",
            "\n",
            "You: what is hackathon about?\n",
            "\n",
            "RAG: The hackathon organized by Educosys is focused on building Agentic Applications that demonstrate intelligent, autonomous, or context-aware behavior. Participants are encouraged to create applications targeting real-world use cases such as productivity, education, automation, customer service, or creative tools. The event emphasizes innovation, creativity, technical depth, usability, and presentation quality. Teams of 1 to 4 members will work on their projects, which will be evaluated based on various criteria, and they will present their work at the end of the hackathon.\n",
            "\n",
            "--- Sources ---\n",
            "[1] source=Educosys_Agentic_Hackathon_Guidelines (5).pdf, page=1\n",
            "[2] source=Educosys_Agentic_Hackathon_Guidelines (5).pdf, page=0\n",
            "[3] source=Educosys_Agentic_Hackathon_Guidelines (5).pdf, page=0\n",
            "---------------\n",
            "\n",
            "You: what is Aetna\n",
            "\n",
            "RAG: Aetna is a health insurance company that provides a range of health care benefits and services, including medical, dental, pharmacy, and behavioral health plans. It is part of the Aetna Passport Network, which includes thousands of in-network doctors and hospitals across the United States. Aetna offers insurance plans to individuals, families, and businesses, and aims to help members access quality health care.\n",
            "\n",
            "--- Sources ---\n",
            "[1] source=Aetna_Tutorial (2).pdf, page=0\n",
            "[2] source=Aetna_Tutorial (2).pdf, page=2\n",
            "[3] source=Educosys_Agentic_Hackathon_Guidelines (5).pdf, page=0\n",
            "---------------\n",
            "\n",
            "You: how to claim insurance\n",
            "\n",
            "RAG: I don't know.\n",
            "\n",
            "--- Sources ---\n",
            "[1] source=Aetna_Tutorial (2).pdf, page=2\n",
            "[2] source=Aetna_Tutorial (2).pdf, page=0\n",
            "[3] source=Aetna_Tutorial (2).pdf, page=1\n",
            "---------------\n",
            "\n",
            "You: how to search doctors\n",
            "\n",
            "RAG: To search for doctors, follow these steps:\n",
            "\n",
            "1. Select a provider option from the given options or type in a specific doctor you are looking for in the search bar.\n",
            "2. Indicate your location and the distance you are willing to travel, then click ‚ÄúSearch‚Äù to proceed.\n",
            "3. If applicable, choose the ‚ÄúPassport to Healthcare¬Æ Primary PPO Network‚Äù before moving to the next step.\n",
            "4. Use the ‚Äúfilter and sort‚Äù feature in your results to add any additional filters you may need.\n",
            "5. To make an appointment, call the provider directly and mention your insurance plan if necessary. \n",
            "\n",
            "If you have further questions, you can contact ISO at (800) 244-1180.\n",
            "\n",
            "--- Sources ---\n",
            "[1] source=Aetna_Tutorial (2).pdf, page=1\n",
            "[2] source=Aetna_Tutorial (2).pdf, page=0\n",
            "[3] source=Aetna_Tutorial (2).pdf, page=2\n",
            "---------------\n",
            "\n",
            "You: exit\n",
            "RAG: Goodbye! üëã\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HG-J0foPkPE8"
      }
    }
  ]
}